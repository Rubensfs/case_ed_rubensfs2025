{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "67f46357-0013-4392-aacf-34748e3166a8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Databricks notebook source\n",
    "# ================================================================\n",
    "# 03_ingest_bronze - Parse dos XMLs e gravação em Delta Bronze\n",
    "# ================================================================\n",
    "from pyspark.sql import SparkSession\n",
    "import xml.etree.ElementTree as ET\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f34967fe-fad3-4a5f-b9af-9f39c0193566",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "dbfs_path = \"/dbfs/mnt/amazonia/raw/xml/\"\n",
    "bronze_table = \"amazonia_catalog.bronze.metadados\"\n",
    "\n",
    "files = [os.path.join(dbfs_path, f) for f in os.listdir(dbfs_path) if f.endswith(\".xml\")]\n",
    "\n",
    "all_rows = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1cc391d0-b2c2-449e-873e-09ab06ecbfe2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "for file in files:\n",
    "    tree = ET.parse(file)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    # Ajustar a tag conforme estrutura real do XML\n",
    "    for elem in root.findall(\".//feature\"):\n",
    "        row = {\n",
    "            \"uuid\": elem.findtext(\"uuid\"),\n",
    "            \"state\": elem.findtext(\"state\"),\n",
    "            \"year\": elem.findtext(\"year\"),\n",
    "            \"area_km\": elem.findtext(\"area_km\"),\n",
    "        }\n",
    "        all_rows.append(row)\n",
    "\n",
    "df = spark.createDataFrame(all_rows)\n",
    "\n",
    "(\n",
    "    df.write.format(\"delta\")\n",
    "    .mode(\"overwrite\")   # use append em produção\n",
    "    .saveAsTable(bronze_table)\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "ig_raw_xml",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
