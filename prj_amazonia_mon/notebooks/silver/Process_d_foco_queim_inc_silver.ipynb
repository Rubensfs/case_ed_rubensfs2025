{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7a8ed4a3-b48e-498b-aa5d-871976e51e77",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# foco_queim_inc_silver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fc74a9ea-51d2-4171-ac48-ef3b627c610f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, lit, when\n",
    "from pyspark.sql.types import DoubleType, StringType, IntegerType, TimestampType\n",
    "from pyspark.sql.types import NumericType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c472cfeb-2e65-4e0b-b0a0-eb0dce4999af",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# WIDGETS / PARÂMETROS\n",
    "# ==============================\n",
    "dbutils.widgets.text(\"catalog\", \"\")\n",
    "dbutils.widgets.text(\"schema_in\", \"\")\n",
    "dbutils.widgets.text(\"table_in\", \"\")\n",
    "dbutils.widgets.text(\"schema_out\", \"\")\n",
    "dbutils.widgets.text(\"table_out\", \"\")\n",
    "dbutils.widgets.text(\"data_ref_carga\", \"\")\n",
    "\n",
    "catalog = dbutils.widgets.get(\"catalog\").strip()\n",
    "schema_in = dbutils.widgets.get(\"schema_in\").strip()\n",
    "table_in = dbutils.widgets.get(\"table_in\").strip()\n",
    "schema_out = dbutils.widgets.get(\"schema_out\").strip()\n",
    "table_out = dbutils.widgets.get(\"table_out\").strip()\n",
    "data_ref_carga = dbutils.widgets.get(\"data_ref_carga\").strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7e9234b8-1faa-4d79-bc04-5423cf3cd6b1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# TRATAMENTO DE ERROS: parâmetros obrigatórios\n",
    "# ==============================\n",
    "params = {\n",
    "    \"catalog\": catalog,\n",
    "    \"schema_in\": schema_in,\n",
    "    \"table_in\": table_in,\n",
    "    \"schema_out\": schema_out,\n",
    "    \"table_out\": table_out,\n",
    "    \"data_ref_carga\": data_ref_carga\n",
    "}\n",
    "missing = [k for k, v in params.items() if v == \"\"]\n",
    "if missing:\n",
    "    raise ValueError(f\"Parâmetros obrigatórios não informados: {', '.join(missing)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "56b474f7-bf80-4b6a-83fa-636f1116d243",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# Formatacao de tabela\n",
    "# ==============================\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "tabela_bronze = f\"{catalog}.{schema_in}.{table_in}\"\n",
    "tabela_silver = f\"{catalog}.{schema_out}.{table_out}\"\n",
    "\n",
    "print(f\"Lendo tabela bronze: {tabela_bronze} - partição data_ref_carga = {data_ref_carga}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "15a3487e-7a68-4865-9b23-ebae1253bc96",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# LEITURA (filtrando por partição)\n",
    "# ==============================\n",
    "try:\n",
    "    df = spark.read.table(tabela_bronze).filter(col(\"data_ref_carga\") == lit(data_ref_carga))\n",
    "except Exception as e:\n",
    "    raise RuntimeError(f\"Erro ao ler a tabela bronze {tabela_bronze}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9702974b-a7e0-4fc7-87f3-3fd048010002",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# TRATAMENTO DE NULOS\n",
    "# =============================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fff05f3b-973e-4c36-98e7-a80cd504ade8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# detectar colunas por tipo\n",
    "string_cols = [f.name for f in df.schema.fields if isinstance(f.dataType, StringType)]\n",
    "numeric_cols = [f.name for f in df.schema.fields if isinstance(f.dataType, NumericType)]\n",
    "\n",
    "# aplicar transformações\n",
    "for c in string_cols:\n",
    "    df = df.withColumn(c, when(col(c).isNull(), lit(\" \")).otherwise(col(c)))\n",
    "\n",
    "for c in numeric_cols:\n",
    "    df = df.withColumn(c, when(col(c).isNull(), lit(0)).otherwise(col(c)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d7775c3d-4ef6-4963-8afa-f6afac39a4fd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# REGRAS DE VALIDAÇÃO / CORREÇÃO\n",
    "# - risco_fogo: valor inválido -999 -> 0 (mantemos os outros valores)\n",
    "# - lat: válido entre -90 e 90 -> caso inválido setar 0\n",
    "# - lon: válido entre -180 e 180 -> caso inválido setar 0\n",
    "# ==============================\n",
    "df = df.withColumn(\"risco_fogo\", when(col(\"risco_fogo\") == -999, lit(0)).otherwise(col(\"risco_fogo\")))\n",
    "df = df.withColumn(\"lat\", when((col(\"lat\") >= -90.0) & (col(\"lat\") <= 90.0), col(\"lat\")).otherwise(lit(0.0)))\n",
    "df = df.withColumn(\"lon\", when((col(\"lon\") >= -180.0) & (col(\"lon\") <= 180.0), col(\"lon\")).otherwise(lit(0.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "34a0a184-9427-4082-b7ac-6e4ff5bf3c90",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# DEFINIÇÃO DOS TIPOS E COMENTÁRIOS PARA A TABELA SILVER\n",
    "# ==============================\n",
    "columns_definition = [\n",
    "    (\"id\", \"STRING\", \"Código único\"),\n",
    "    (\"lat\", \"DOUBLE\", \"Latitude do centro do píxel de fogo ativo apresentada em unidade de graus decimais\"),\n",
    "    (\"lon\", \"DOUBLE\", \"Longitude do centro do píxel de fogo ativo apresentada em unidade de graus decimais\"),\n",
    "    (\"data_hora_gmt\", \"TIMESTAMP\", \"Horário de referência da passagem do satélite segundo o fuso horário de Greenwich (GMT). Formato: YYYY-MM-DDTHH:MM:SS.sss+00:00\"),\n",
    "    (\"satelite\", \"STRING\", \"Nome do algoritmo utilizado e referência ao satélite provedor da imagem.\"),\n",
    "    (\"municipio\", \"STRING\", \"Nome do município. Para o Brasil foi utilizado como referência o dado do IBGE 2000.\"),\n",
    "    (\"estado\", \"STRING\", \"Nome do estado (nível 1 do GADM).\"),\n",
    "    (\"pais\", \"STRING\", \"Nome do País (nível 0 do GADM).\"),\n",
    "    (\"municipio_id\", \"INT\", \"Código/ID do município (referência IBGE quando aplicável).\"),\n",
    "    (\"estado_id\", \"INT\", \"Código do estado\"),\n",
    "    (\"pais_id\", \"INT\", \"Código do país\"),\n",
    "    (\"numero_dias_sem_chuva\", \"INT\", \"Número de dias sem chuva até a detecção do foco.\"),\n",
    "    (\"precipitacao\", \"DOUBLE\", \"Valor da precipitação acumulada no dia até o momento da detecção do foco.\"),\n",
    "    (\"risco_fogo\", \"DOUBLE\", \"Valor do Risco de Fogo previsto para o dia da detecção do foco. Valores inválidos -999 foram setados para 0.\"),\n",
    "    (\"bioma\", \"STRING\", \"Nome do Bioma segundo referência do IBGE 2004. Para outros países o campo pode ficar nulo (representado como ' ').\"),\n",
    "    (\"frp\", \"DOUBLE\", \"Fire Radiative Power, MW (megawatts).\"),\n",
    "    (\"data_ref_carga\", \"STRING\", \"Data do processamento da partição (YYYY-MM-DD)\")\n",
    "]\n",
    "\n",
    "# descrição geral da tabela\n",
    "descricao_tabela = (\n",
    "    \"Tabela Silver - Focos de Queimadas e Incêndios (tratada).\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a4635531-6f3a-4d61-8dfa-5d978f03621f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# CRIAR TABELA SE NÃO EXISTIR (COM OS COMENTÁRIOS) OU SOBRESCREVER DADOS SE EXISTIR\n",
    "# ==============================\n",
    "from pyspark.sql.utils import AnalysisException\n",
    "\n",
    "def create_table_with_comments(table_fqdn, columns_def, partition_col, table_description):\n",
    "    # monta definição de colunas para CREATE TABLE\n",
    "    cols_sql = \",\\n  \".join([f\"{name} {dtype} COMMENT '{comment}'\" for name, dtype, comment in columns_def])\n",
    "    sql = f\"\"\"\n",
    "    CREATE TABLE {table_fqdn} (\n",
    "      {cols_sql}\n",
    "    )\n",
    "    USING DELTA\n",
    "    PARTITIONED BY ({partition_col})\n",
    "    \"\"\"\n",
    "    # criar tabela\n",
    "    spark.sql(sql)\n",
    "    # setar descrição\n",
    "    spark.sql(f\"ALTER TABLE {table_fqdn} SET TBLPROPERTIES (description = '{table_description}')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "20e5935a-fac8-4534-8957-a6042cf22fca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# verifica existência\n",
    "table_exists = spark.catalog._jcatalog.tableExists(tabela_silver)  # uso interno catalog para suportar catalog.schema.table\n",
    "\n",
    "if not table_exists:\n",
    "    print(f\"Tabela {tabela_silver} não existe. Criando com comentários...\")\n",
    "    try:\n",
    "        create_table_with_comments(tabela_silver, columns_definition, \"data_ref_carga\", descricao_tabela)\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Erro ao criar tabela silver {tabela_silver}: {e}\")\n",
    "else:\n",
    "    print(f\"Tabela {tabela_silver} já existe. Irei gravar dados e atualizar comentários das colunas (se necessário).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "93e71eda-dba7-44ba-8d89-2518fcab658b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# GRAVANDO DADOS NA TABELA SILVER (por partição)\n",
    "# - Usamos overwrite forçando apenas a partição específica para evitar perder histórico\n",
    "# ==============================\n",
    "try:\n",
    "    # opção: sobrescrever apenas a partição específica (modo compatível com Delta)\n",
    "    (\n",
    "        df.write\n",
    "        .format(\"delta\")\n",
    "        .mode(\"overwrite\")\n",
    "        .option(\"overwriteSchema\", \"true\")\n",
    "        .partitionBy(\"data_ref_carga\")\n",
    "        .saveAsTable(tabela_silver)\n",
    "    )\n",
    "    print(\"Gravação realizada com sucesso na tabela silver.\")\n",
    "except Exception as e:\n",
    "    raise RuntimeError(f\"Erro ao gravar na tabela silver {tabela_silver}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d1d070fd-48c0-4d30-81d4-578a468e5816",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# FIM - resumo / contagem de registros\n",
    "# ==============================\n",
    "record_count = df.count()\n",
    "print(f\"Registros processados para data_ref_carga={data_ref_carga}: {record_count}\")\n",
    "print(\"Job finalizado com sucesso ✅\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Process_d_foco_queim_inc_silver",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
