{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7a8ed4a3-b48e-498b-aa5d-871976e51e77",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# foco_queim_inc_silver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fc74a9ea-51d2-4171-ac48-ef3b627c610f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, lit, when, trim\n",
    "from pyspark.sql.types import DoubleType, StringType, IntegerType, TimestampType, NumericType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c472cfeb-2e65-4e0b-b0a0-eb0dce4999af",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# WIDGETS / PAR√ÇMETROS\n",
    "# ==============================\n",
    "dbutils.widgets.text(\"catalog\", \"\")\n",
    "dbutils.widgets.text(\"schema_in\", \"\")\n",
    "dbutils.widgets.text(\"table_in\", \"\")\n",
    "dbutils.widgets.text(\"schema_out\", \"\")\n",
    "dbutils.widgets.text(\"table_out\", \"\")\n",
    "dbutils.widgets.text(\"data_ref_carga\", \"\")\n",
    "\n",
    "catalog = dbutils.widgets.get(\"catalog\").strip()\n",
    "schema_in = dbutils.widgets.get(\"schema_in\").strip()\n",
    "table_in = dbutils.widgets.get(\"table_in\").strip()\n",
    "schema_out = dbutils.widgets.get(\"schema_out\").strip()\n",
    "table_out = dbutils.widgets.get(\"table_out\").strip()\n",
    "data_ref_carga = dbutils.widgets.get(\"data_ref_carga\").strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7e9234b8-1faa-4d79-bc04-5423cf3cd6b1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# TRATAMENTO DE ERROS: par√¢metros obrigat√≥rios\n",
    "# ==============================\n",
    "params = {\n",
    "    \"catalog\": catalog,\n",
    "    \"schema_in\": schema_in,\n",
    "    \"table_in\": table_in,\n",
    "    \"schema_out\": schema_out,\n",
    "    \"table_out\": table_out,\n",
    "    \"data_ref_carga\": data_ref_carga\n",
    "}\n",
    "missing = [k for k, v in params.items() if v == \"\"]\n",
    "if missing:\n",
    "    raise ValueError(f\"Par√¢metros obrigat√≥rios n√£o informados: {', '.join(missing)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "56b474f7-bf80-4b6a-83fa-636f1116d243",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# Formatacao de tabela\n",
    "# ==============================\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "tabela_bronze = f\"{catalog}.{schema_in}.{table_in}\"\n",
    "tabela_silver = f\"{catalog}.{schema_out}.{table_out}\"\n",
    "\n",
    "print(f\"Lendo tabela bronze: {tabela_bronze} - parti√ß√£o data_ref_carga = {data_ref_carga}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "15a3487e-7a68-4865-9b23-ebae1253bc96",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# LEITURA (filtrando por parti√ß√£o)\n",
    "# ==============================\n",
    "try:\n",
    "    df = spark.read.table(tabela_bronze).filter(col(\"data_ref_carga\") == lit(data_ref_carga))\n",
    "except Exception as e:\n",
    "    raise RuntimeError(f\"Erro ao ler a tabela bronze {tabela_bronze}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9702974b-a7e0-4fc7-87f3-3fd048010002",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# TRATAMENTO DE NULOS\n",
    "# =============================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fff05f3b-973e-4c36-98e7-a80cd504ade8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# detectar colunas por tipo\n",
    "string_cols = [f.name for f in df.schema.fields if isinstance(f.dataType, StringType)]\n",
    "numeric_cols = [f.name for f in df.schema.fields if isinstance(f.dataType, NumericType)]\n",
    "\n",
    "# aplicar transforma√ß√µes\n",
    "for c in string_cols:\n",
    "    df = df.withColumn(c, when(col(c).isNull(), lit(\" \")).otherwise(col(c)))\n",
    "\n",
    "for c in numeric_cols:\n",
    "    df = df.withColumn(c, when(col(c).isNull(), lit(0)).otherwise(col(c)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9569e636-4252-4ddc-8fa5-c552a380849c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CONVERS√ïES PARA TIPOS NUM√âRICOS (com fallback = 0)\n",
    "# ============================================================\n",
    "df = (\n",
    "    df\n",
    "    .withColumn(\n",
    "        \"numero_dias_sem_chuva\",\n",
    "        when(trim(col(\"numero_dias_sem_chuva\")) == \"\", lit(0))\n",
    "        .otherwise(col(\"numero_dias_sem_chuva\").cast(IntegerType()))\n",
    "    )\n",
    "    .withColumn(\n",
    "        \"precipitacao\",\n",
    "        when(trim(col(\"precipitacao\")) == \"\", lit(0.0))\n",
    "        .otherwise(col(\"precipitacao\").cast(DoubleType()))\n",
    "    )\n",
    "    .withColumn(\n",
    "        \"risco_fogo\",\n",
    "        when(trim(col(\"risco_fogo\")) == \"\", lit(0.0))\n",
    "        .otherwise(col(\"risco_fogo\").cast(DoubleType()))\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d7775c3d-4ef6-4963-8afa-f6afac39a4fd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# REGRAS DE VALIDA√á√ÉO / CORRE√á√ÉO\n",
    "# ==============================\n",
    "df = df.withColumn(\"risco_fogo\", when(col(\"risco_fogo\") == -999, lit(0)).otherwise(col(\"risco_fogo\")))\n",
    "df = df.withColumn(\"lat\", when((col(\"lat\") >= -90.0) & (col(\"lat\") <= 90.0), col(\"lat\")).otherwise(lit(0.0)))\n",
    "df = df.withColumn(\"lon\", when((col(\"lon\") >= -180.0) & (col(\"lon\") <= 180.0), col(\"lon\")).otherwise(lit(0.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "34a0a184-9427-4082-b7ac-6e4ff5bf3c90",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# DEFINI√á√ÉO DOS TIPOS E COMENT√ÅRIOS PARA A TABELA SILVER\n",
    "# ==============================\n",
    "columns_definition = [\n",
    "    (\"id\", \"STRING\", \"C√≥digo √∫nico\"),\n",
    "    (\"lat\", \"DOUBLE\", \"Latitude do centro do p√≠xel de fogo ativo apresentada em unidade de graus decimais\"),\n",
    "    (\"lon\", \"DOUBLE\", \"Longitude do centro do p√≠xel de fogo ativo apresentada em unidade de graus decimais\"),\n",
    "    (\"data_hora_gmt\", \"TIMESTAMP\", \"Hor√°rio de refer√™ncia da passagem do sat√©lite segundo o fuso hor√°rio de Greenwich (GMT). Formato: YYYY-MM-DDTHH:MM:SS.sss+00:00\"),\n",
    "    (\"satelite\", \"STRING\", \"Nome do algoritmo utilizado e refer√™ncia ao sat√©lite provedor da imagem.\"),\n",
    "    (\"municipio\", \"STRING\", \"Nome do munic√≠pio. Para o Brasil foi utilizado como refer√™ncia o dado do IBGE 2000.\"),\n",
    "    (\"estado\", \"STRING\", \"Nome do estado (n√≠vel 1 do GADM).\"),\n",
    "    (\"pais\", \"STRING\", \"Nome do Pa√≠s (n√≠vel 0 do GADM).\"),\n",
    "    (\"municipio_id\", \"INT\", \"C√≥digo/ID do munic√≠pio (refer√™ncia IBGE quando aplic√°vel).\"),\n",
    "    (\"estado_id\", \"INT\", \"C√≥digo do estado\"),\n",
    "    (\"pais_id\", \"INT\", \"C√≥digo do pa√≠s\"),\n",
    "    (\"numero_dias_sem_chuva\", \"INT\", \"N√∫mero de dias sem chuva at√© a detec√ß√£o do foco.\"),\n",
    "    (\"precipitacao\", \"DOUBLE\", \"Valor da precipita√ß√£o acumulada no dia at√© o momento da detec√ß√£o do foco.\"),\n",
    "    (\"risco_fogo\", \"DOUBLE\", \"Valor do Risco de Fogo previsto para o dia da detec√ß√£o do foco. Valores inv√°lidos -999 foram setados para 0.\"),\n",
    "    (\"bioma\", \"STRING\", \"Nome do Bioma segundo refer√™ncia do IBGE 2004. Para outros pa√≠ses o campo pode ficar nulo (representado como ' ').\"),\n",
    "    (\"frp\", \"DOUBLE\", \"Fire Radiative Power, MW (megawatts).\"),\n",
    "    (\"data_ref_carga\", \"STRING\", \"Data do processamento da parti√ß√£o (YYYY-MM-DD)\")\n",
    "]\n",
    "\n",
    "# descri√ß√£o geral da tabela\n",
    "descricao_tabela = (\n",
    "    \"Tabela Silver - Focos de Queimadas e Inc√™ndios (tratada).\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a4635531-6f3a-4d61-8dfa-5d978f03621f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# CRIAR TABELA SE N√ÉO EXISTIR (COM OS COMENT√ÅRIOS) OU SOBRESCREVER DADOS SE EXISTIR\n",
    "# ==============================\n",
    "from pyspark.sql.utils import AnalysisException\n",
    "\n",
    "def create_table_with_comments(table_fqdn, columns_def, partition_col, table_description):\n",
    "    \"\"\"\n",
    "    Cria a tabela usando os tipos e coment√°rios informados.\n",
    "    Faz escape de aspas simples nos coment√°rios para evitar SQL parse errors.\n",
    "    \"\"\"\n",
    "    # Fun√ß√£o utilit√°ria para escapar coment√°rios para SQL (substitui ' por '')\n",
    "    def escape_comment_for_sql(text: str) -> str:\n",
    "        if text is None:\n",
    "            return \"\"\n",
    "        # substitui ' por '' (padr√£o SQL) e remove quebras de linha n√£o desejadas\n",
    "        return text.replace(\"'\", \"''\").replace(\"\\n\", \" \").replace(\"\\r\", \" \")\n",
    "\n",
    "    cols_parts = []\n",
    "    for name, dtype, comment in columns_def:\n",
    "        safe_comment = escape_comment_for_sql(comment)\n",
    "        cols_parts.append(f\"{name} {dtype} COMMENT '{safe_comment}'\")\n",
    "\n",
    "    cols_sql = \",\\n  \".join(cols_parts)\n",
    "\n",
    "    sql = f\"\"\"\n",
    "    CREATE TABLE {table_fqdn} (\n",
    "      {cols_sql}\n",
    "    )\n",
    "    USING DELTA\n",
    "    PARTITIONED BY ({partition_col})\n",
    "    \"\"\"\n",
    "\n",
    "    # executa cria√ß√£o\n",
    "    spark.sql(sql)\n",
    "\n",
    "    # setar descri√ß√£o da tabela (escape tamb√©m)\n",
    "    safe_table_description = escape_comment_for_sql(table_description)\n",
    "    spark.sql(f\"ALTER TABLE {table_fqdn} SET TBLPROPERTIES (description = '{safe_table_description}')\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "20e5935a-fac8-4534-8957-a6042cf22fca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# verifica exist√™ncia\n",
    "table_exists = spark.catalog.tableExists(tabela_silver)  # uso interno catalog para suportar catalog.schema.table\n",
    "\n",
    "if not table_exists:\n",
    "    print(f\"Tabela {tabela_silver} n√£o existe. Criando com coment√°rios...\")\n",
    "    try:\n",
    "        create_table_with_comments(\n",
    "            tabela_silver,\n",
    "            columns_definition,\n",
    "            \"data_ref_carga\",\n",
    "            descricao_tabela\n",
    "        )\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Erro ao criar tabela silver {tabela_silver}: {e}\")\n",
    "else:\n",
    "    print(f\"Tabela {tabela_silver} j√° existe. Irei gravar dados e atualizar coment√°rios das colunas (se necess√°rio).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b791847d-66d9-44fa-93ff-88b02528c114",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, trim, when, lit\n",
    "from pyspark.sql.types import NumericType, StringType, DateType, TimestampType\n",
    "\n",
    "def sanitize_and_cast(df, tabela_destino: str):\n",
    "    \"\"\"\n",
    "    Alinha DataFrame ao schema da tabela destino e remove valores inv√°lidos.\n",
    "    Garante tipos corretos ANTES da escrita Delta.\n",
    "    \"\"\"\n",
    "    schema_destino = spark.table(tabela_destino).schema\n",
    "    df_sel = df.select([c for c in df.columns if c in [f.name for f in schema_destino]])\n",
    "\n",
    "    for field in schema_destino:\n",
    "        nome = field.name\n",
    "        tipo = field.dataType\n",
    "\n",
    "        if nome not in df_sel.columns:\n",
    "            continue\n",
    "\n",
    "        # üßπ 1. Remove espa√ßos e strings vazias\n",
    "        df_sel = df_sel.withColumn(nome, trim(col(nome)))\n",
    "        df_sel = df_sel.withColumn(nome, when((col(nome) == \"\") | (col(nome).isNull()), lit(None)).otherwise(col(nome)))\n",
    "\n",
    "        # üî¢ 2. Trata tipos num√©ricos\n",
    "        if isinstance(tipo, NumericType):\n",
    "            df_sel = df_sel.withColumn(\n",
    "                nome,\n",
    "                when(\n",
    "                    col(nome).rlike(\"^[+-]?\\\\d+(\\\\.\\\\d+)?$\"),\n",
    "                    col(nome).cast(tipo.simpleString())\n",
    "                ).otherwise(lit(None).cast(tipo.simpleString()))\n",
    "            )\n",
    "\n",
    "        # üïì 3. Trata timestamps e datas\n",
    "        elif isinstance(tipo, (TimestampType, DateType)):\n",
    "            df_sel = df_sel.withColumn(nome, col(nome).cast(tipo.simpleString()))\n",
    "\n",
    "        # üî§ 4. Strings apenas limpam espa√ßos\n",
    "        elif isinstance(tipo, StringType):\n",
    "            df_sel = df_sel.withColumn(nome, when(col(nome) == \"\", lit(None)).otherwise(col(nome)))\n",
    "\n",
    "        else:\n",
    "            df_sel = df_sel.withColumn(nome, col(nome).cast(tipo.simpleString()))\n",
    "\n",
    "    return df_sel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "756ffd95-24f7-4430-8ca3-bb6de7d00e4d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Limpa e ajusta schema antes de gravar na tabela destino\n",
    "df_sanitized = sanitize_and_cast(df, tabela_silver)\n",
    "display(df_sanitized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5af1dd2a-68b7-466c-8941-5f57fda652b7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# 1Ô∏è‚É£ Fun√ß√£o para reaplicar coment√°rios\n",
    "# ==============================\n",
    "def apply_table_comments(table_fqdn: str, columns_def: list, table_description: str):\n",
    "    \"\"\"\n",
    "    Aplica coment√°rios em colunas e descri√ß√£o da tabela no Delta.\n",
    "    \"\"\"\n",
    "    def escape_comment(text):\n",
    "        return (text or \"\").replace(\"'\", \"''\").replace(\"\\n\", \" \").replace(\"\\r\", \" \")\n",
    "\n",
    "    # Alterar coment√°rio das colunas\n",
    "    for name, _, comment in columns_def:\n",
    "        safe_comment = escape_comment(comment)\n",
    "        spark.sql(f\"ALTER TABLE {table_fqdn} CHANGE COLUMN {name} COMMENT '{safe_comment}'\")\n",
    "\n",
    "    # Alterar descri√ß√£o da tabela\n",
    "    safe_table_description = escape_comment(table_description)\n",
    "    spark.sql(f\"ALTER TABLE {table_fqdn} SET TBLPROPERTIES (description = '{safe_table_description}')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "93e71eda-dba7-44ba-8d89-2518fcab658b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# GRAVANDO DADOS NA TABELA SILVER (por parti√ß√£o)\n",
    "# - Usamos overwrite for√ßando apenas a parti√ß√£o espec√≠fica para evitar perder hist√≥rico\n",
    "# ==============================\n",
    "try:\n",
    "    # op√ß√£o: sobrescrever apenas a parti√ß√£o espec√≠fica (modo compat√≠vel com Delta)\n",
    "    (\n",
    "        df_sanitized.write\n",
    "        .format(\"delta\")\n",
    "        .mode(\"overwrite\")\n",
    "        .option(\"overwriteSchema\", \"false\")\n",
    "        .partitionBy(\"data_ref_carga\")\n",
    "        .saveAsTable(tabela_silver)\n",
    "    )\n",
    "    print(\"Grava√ß√£o realizada com sucesso na tabela silver.\")\n",
    "except Exception as e:\n",
    "    raise RuntimeError(f\"Erro ao gravar na tabela silver {tabela_silver}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b133c165-c785-4dbc-89dc-5dbf058e3a76",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# 5Ô∏è‚É£ Reaplicar coment√°rios e descri√ß√£o\n",
    "# ==============================\n",
    "apply_table_comments(tabela_silver, columns_definition, descricao_tabela)\n",
    "print(\"Coment√°rios e descri√ß√£o reaplicados ‚úÖ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d1d070fd-48c0-4d30-81d4-578a468e5816",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# FIM - resumo / contagem de registros\n",
    "# ==============================\n",
    "record_count = df.count()\n",
    "print(f\"Registros processados para data_ref_carga={data_ref_carga}: {record_count}\")\n",
    "print(\"Job finalizado com sucesso ‚úÖ\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Process_d_foco_queim_inc_silver",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
