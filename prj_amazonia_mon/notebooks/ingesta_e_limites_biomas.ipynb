{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b0b9b629-9631-45ea-a344-610c69a4a385",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#Processamento de Raw XML to bronze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "265a85f5-2dfa-42f3-a7e4-6421bef0c44a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# Bronze - Importar XML (IBGE)\n",
    "# ================================================================\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import SparkSession\n",
    "from datetime import datetime\n",
    "import os\n",
    "import xml.etree.ElementTree as ET\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "19b95e59-1846-4f23-be03-d9b75b441035",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"Processamento_raw_xml_to_bronze\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4cf75173-b54a-440b-952e-acd8256e5b6a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# Par√¢metro recebido via Job Databricks\n",
    "# ================================================================\n",
    "dbutils.widgets.text(\"data_ref_carga\", \"\")\n",
    "data_ref_carga = dbutils.widgets.get(\"data_ref_carga\")\n",
    "\n",
    "if not data_ref_carga:\n",
    "    raise ValueError(\"‚ùå Par√¢metro 'data_ref_carga' n√£o informado (formato esperado: yyyy-MM-dd)\")\n",
    "\n",
    "print(f\"üóìÔ∏è Data de refer√™ncia da carga: {data_ref_carga}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "229a8623-8f79-427f-acb9-a8d2c4c9d9cf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# 1Ô∏è‚É£ Configura√ß√µes\n",
    "# ===============================================================\n",
    "catalog = \"datamasters\"\n",
    "schema = \"b_tbra\"\n",
    "data_log = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "path_raw = \"/Volumes/datamasters/raw/raw_tbra/\"\n",
    "display(dbutils.fs.ls(\"/Volumes/datamasters/raw/raw_tbra/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9b4b7807-6630-47eb-8ac9-592e877bbfd5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# 2Ô∏è‚É£ Listar arquivos XML\n",
    "# ================================================================\n",
    "arquivos = [f.path.rstrip(\"/\") for f in dbutils.fs.ls(path_raw) if f.name.lower().endswith(\".xml\")]\n",
    "print(\"üìÇ Arquivos XML encontrados:\")\n",
    "for a in arquivos:\n",
    "    print(\"-\", a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "34512df9-e8ca-4a02-941f-b27ffa1d995b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# 3Ô∏è‚É£ Detectar automaticamente a tag raiz (rowTag)\n",
    "# ================================================================\n",
    "def detectar_rowtag(arquivo_dbfs):\n",
    "    try:\n",
    "        xml_str = dbutils.fs.head(arquivo_dbfs, 32768)  # l√™ at√© 32 KB\n",
    "        root = ET.fromstring(xml_str)\n",
    "        return root.tag\n",
    "    except Exception:\n",
    "        try:\n",
    "            df_tmp = spark.read.format(\"com.databricks.spark.xml\").option(\"rowTag\", \"*\").load(arquivo_dbfs)\n",
    "            return df_tmp.columns[0] if df_tmp.columns else \"root\"\n",
    "        except:\n",
    "            return \"root\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c7763582-1373-4b47-8d0d-77d6aa1f78f7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# 3Ô∏è‚É£ Inicializa lista de logs\n",
    "# ================================================================\n",
    "logs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e4e924e8-8bd1-4c20-ac0c-65609d0199da",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# 5Ô∏è‚É£ Processar arquivos XML\n",
    "# ================================================================\n",
    "\n",
    "for arquivo in arquivos:\n",
    "    nome_arquivo = os.path.basename(arquivo)\n",
    "    # prefixo \"e_\" + nome do arquivo em min√∫sculas, sem espa√ßos\n",
    "    nome_tabela = \"e_\" + os.path.splitext(nome_arquivo)[0].lower().replace(\" \", \"_\")\n",
    "\n",
    "    print(f\"\\nüöÄ Processando {nome_arquivo} -> {catalog}.{schema}.{nome_tabela}\")\n",
    "\n",
    "    row_tag = detectar_rowtag(arquivo)\n",
    "    print(f\"   üîé rowTag detectado: {row_tag}\")\n",
    "\n",
    "    status = \"OK\"\n",
    "    erro_msg = \"\"\n",
    "    inicio = datetime.now()\n",
    "    qtd_registros = 0\n",
    "\n",
    "    try:\n",
    "        # Ler XML\n",
    "        df_xml = spark.read.format(\"com.databricks.spark.xml\") \\\n",
    "            .option(\"rowTag\", \"gmd:MD_Metadata\") \\\n",
    "            .option(\"inferSchema\", \"true\") \\\n",
    "            .option(\"ignoreNamespace\", \"true\") \\\n",
    "            .load(arquivo)\n",
    "        \n",
    "        # Adiciona coluna de parti√ß√£o √∫nica\n",
    "        df_xml = df_xml.withColumn(\"data_ref_carga\", F.lit(data_ref_carga))\n",
    "\n",
    "        # Contar registros\n",
    "        qtd_registros = df_xml.count()\n",
    "\n",
    "        # Gravar tabela Delta particionada\n",
    "        df_xml.write.format(\"delta\") \\\n",
    "            .mode(\"overwrite\") \\\n",
    "            .option(\"overwriteSchema\", \"true\") \\\n",
    "            .saveAsTable(f\"{catalog}.{schema}.{nome_tabela}\")\n",
    "\n",
    "        print(f\"‚úÖ Tabela gravada: {catalog}.{schema}.{nome_tabela} ({qtd_registros} registros)\")\n",
    "\n",
    "    except Exception as e:\n",
    "        status = \"ERRO\"\n",
    "        erro_msg = str(e)\n",
    "        print(f\"‚ùå Erro ao processar {nome_arquivo}: {erro_msg}\")\n",
    "\n",
    "    fim = datetime.now()\n",
    "    duracao = round((fim - inicio).total_seconds(), 2)\n",
    "\n",
    "    # Registrar log\n",
    "    logs.append(\n",
    "        (\n",
    "            nome_arquivo,\n",
    "            nome_tabela,\n",
    "            row_tag,\n",
    "            status,\n",
    "            erro_msg,\n",
    "            data_log,\n",
    "            data_ref_carga,\n",
    "            qtd_registros,\n",
    "            duracao,\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Mostrar logs finais\n",
    "df_logs = spark.createDataFrame(logs, schema=[\n",
    "    \"arquivo\",\n",
    "    \"tabela\",\n",
    "    \"row_tag\",\n",
    "    \"status\",\n",
    "    \"erro_msg\",\n",
    "    \"data_log\",\n",
    "    \"data_ref_carga\",\n",
    "    \"qtd_registros\",\n",
    "    \"duracao_segundos\"\n",
    "])\n",
    "display(df_logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "429cc74b-959f-4d37-aa28-fadc448887c9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# 6Ô∏è‚É£ Gravar Log T√©cnico\n",
    "# ================================================================\n",
    "df_log = spark.createDataFrame(\n",
    "    logs,\n",
    "    [\n",
    "        \"arquivo\",\n",
    "        \"tabela\",\n",
    "        \"rowTag_detectado\",\n",
    "        \"status\",\n",
    "        \"mensagem\",\n",
    "        \"data_log\",\n",
    "        \"data_ref_carga\",\n",
    "        \"linhas_lidas\",\n",
    "        \"duracao_segundos\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "(\n",
    "    df_log.write\n",
    "    .format(\"delta\")\n",
    "    .mode(\"append\")\n",
    "    .option(\"mergeSchema\", \"true\")\n",
    "    .saveAsTable(f\"{catalog}.{schema}.log_carga_xml\")\n",
    ")\n",
    "\n",
    "print(\"\\nüóíÔ∏è Log salvo em:\", f\"{catalog}.{schema}.log_carga_xml\")\n",
    "print(\"üéØ Processo conclu√≠do para todos os XMLs.\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "ingesta_e_limites_biomas",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
